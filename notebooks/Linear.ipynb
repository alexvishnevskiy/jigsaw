{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e895afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a36650",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/alexander/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexander/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/alexander/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/alexander/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jigsaw.models.linear_models.base_model import LinearModel, KernelModel, SVRModel\n",
    "from jigsaw.models.cnn_models.base_model import CnnModel\n",
    "from jigsaw.models.rnn_models.base_model import RnnModel\n",
    "from jigsaw.utils.tokenizer import Tokenizer\n",
    "from box import Box\n",
    "from jigsaw.utils.glove import load_glove\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from jigsaw.scripts.training import linear_train\n",
    "from jigsaw.scripts.inference import linear_predict\n",
    "from jigsaw.utils.cleaning import *\n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9c99296",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'seed': 42,\n",
    "    'emb_type': 'fasttext',\n",
    "    'model_type': 'linear',\n",
    "    'project': 'Jigsaw',\n",
    "    'dataset': {\n",
    "        'name': 'toxic-comment-preprocessed',\n",
    "        'more_toxic': 'more_toxic',\n",
    "        'less_toxic': 'less_toxic',\n",
    "        'text_col': 'comment_text',\n",
    "        'target_col': 'y'\n",
    "    },\n",
    "    'cache_features': True,\n",
    "    'alpha': 1,\n",
    "    'ngram_range': (2, 5),\n",
    "    'kernel': 'poly',\n",
    "    'gamma': 'scale',\n",
    "    'degree': 3,\n",
    "    'C': 1,\n",
    "    'max_df': 1,\n",
    "    'min_df': 1,\n",
    "    'emb_size': 100,\n",
    "    'out_channels': 10,\n",
    "    'num_classes': 1,\n",
    "    'load_embeddings': True,\n",
    "    'rnn_embeddings': False,\n",
    "    'freeze_embeddings': True,\n",
    "    'emb_path': '/Users/alexander/Documents/jigsaw/vectors/fast_text/model_100_5.bin',\n",
    "    'save_path': '../models/linear/fasttext/fasttext.joblib',\n",
    "    'sample_submission': '../data/jigsaw-rate-severity/sample_submission.csv',\n",
    "    'output_dir': '.'\n",
    "}\n",
    "cfg = Box(cfg)\n",
    "t = Tokenizer()\n",
    "t.fit(train_df)\n",
    "cfg['tokenizer'] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e80ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfifdf_preprocess(data, col):\n",
    "    data[col] = links_removing(data, col)\n",
    "    data[col] = remove_stopwords(data, col)\n",
    "    data[col] = preprocess_from_kaggle(data, col)\n",
    "    data[col] = preprocess_slang_sub(data, col)\n",
    "    data[col] = lemmatize(data, col)\n",
    "    data[col] = remove_punctuation(data, col)\n",
    "    data[col] = data[col].apply(lambda x: replaceMultiToxicWords(x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "529690b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train(df):\n",
    "    toxic_comment_w = {\n",
    "        'identity_hate': 1.18323494807095,\n",
    "        'insult': 0.3844723322363254,\n",
    "        'obscene': 1.241559480304455,\n",
    "        'severe_toxic': 1.147691258564159,\n",
    "        'threat': 1.273216379557446,\n",
    "        'toxic': 1.966945011013778\n",
    "    }\n",
    "    \n",
    "    for col, v in toxic_comment_w.items():\n",
    "        df[col] *= toxic_comment_w[col]\n",
    "        df['y'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)\n",
    "        df['y'] = df['y']/df['y'].max()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "060bc11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_val(df):\n",
    "  df_new = df.copy()\n",
    "  df_new['pair'] = df_new.apply(lambda x:\" \".join(sorted((x['less_toxic'],\n",
    "                                                  x['more_toxic']))),axis=1)\n",
    "  df_new['pair_hash'] = df_new.pair.apply(lambda x: str(abs(hash(x)) % (10 ** 8)))\n",
    "  del df_new['pair']\n",
    "\n",
    "  df_new['pair_cnt']=df_new.groupby(['pair_hash'])['worker'].transform(lambda x: x.count())\n",
    "\n",
    "  df_new['cnt']=df_new.groupby(['pair_hash', \n",
    "                        'less_toxic',\n",
    "                        'more_toxic'])['worker'].transform(lambda x: x.count())\n",
    "  df_new = df_new[~((df_new.pair_cnt == 3) & (df_new.cnt == 1))][['worker', 'less_toxic', 'more_toxic']]\n",
    "  df_new = df_new.drop_duplicates(subset = ['less_toxic', 'more_toxic'])\n",
    "  df_new.index = range(len(df_new))\n",
    "  return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9894805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/jigsaw-rate-severity/validation_data.csv')\n",
    "df = clean_val(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "301cd749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/preprocessed_data/jigsaw-toxic-comment_lemmatize.csv')\n",
    "val_df = pd.read_csv('../data/preprocessed_data/validation_data_lemmatize.csv')\n",
    "test_df = pd.read_csv('../data/jigsaw-rate-severity/comments_to_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319c7f9b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_train(cfg, train_df, val_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
